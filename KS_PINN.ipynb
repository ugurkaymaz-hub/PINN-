{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Kuramoto-Sivashinsky Denklemi PINN Modeli\n",
        "# âˆ‚u/âˆ‚t + u*âˆ‚u/âˆ‚x + âˆ‚Â²u/âˆ‚xÂ² + âˆ‚â´u/âˆ‚xâ´ = 0\n",
        "# Kaotik davranÄ±ÅŸ gÃ¶steren 4. dereceden nonlinear PDE\n",
        "\n",
        "print(\"Kuramoto-Sivashinsky Denklemi PINN Modeli\")\n",
        "print(\"=\" * 50)\n",
        "print(\"PDE: âˆ‚u/âˆ‚t + u*âˆ‚u/âˆ‚x + âˆ‚Â²u/âˆ‚xÂ² + âˆ‚â´u/âˆ‚xâ´ = 0\")\n",
        "print(\"Domain: x âˆˆ [0, 2Ï€], t âˆˆ [0, T]\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Model parametreleri\n",
        "L = 2 * np.pi  # Spatial domain [0, 2Ï€]\n",
        "T = 10.0       # Time domain [0, T]\n",
        "n_hidden = 128 # Hidden layer boyutu\n",
        "n_layers = 4   # Layer sayÄ±sÄ±\n",
        "\n",
        "# Neural Network modeli\n",
        "def create_ks_model():\n",
        "    \"\"\"Kuramoto-Sivashinsky iÃ§in Ã¶zel PINN modeli\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(n_hidden, activation='tanh', input_shape=(2,)),\n",
        "        tf.keras.layers.Dense(n_hidden, activation='tanh'),\n",
        "        tf.keras.layers.Dense(n_hidden, activation='tanh'),\n",
        "        tf.keras.layers.Dense(n_hidden, activation='tanh'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Kuramoto-Sivashinsky PDE residual hesaplama\n",
        "@tf.function\n",
        "def ks_physics_loss(model, x, t):\n",
        "    \"\"\"\n",
        "    KS denklemi: âˆ‚u/âˆ‚t + u*âˆ‚u/âˆ‚x + âˆ‚Â²u/âˆ‚xÂ² + âˆ‚â´u/âˆ‚xâ´ = 0\n",
        "    \"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape4:\n",
        "        tape4.watch([x, t])\n",
        "        with tf.GradientTape(persistent=True) as tape3:\n",
        "            tape3.watch([x, t])\n",
        "            with tf.GradientTape(persistent=True) as tape2:\n",
        "                tape2.watch([x, t])\n",
        "                with tf.GradientTape(persistent=True) as tape1:\n",
        "                    tape1.watch([x, t])\n",
        "                    u = model(tf.stack([x, t], axis=1))\n",
        "\n",
        "                # 1. dereceden tÃ¼revler\n",
        "                du_dx = tape1.gradient(u, x)\n",
        "                du_dt = tape1.gradient(u, t)\n",
        "\n",
        "            # 2. dereceden tÃ¼revler\n",
        "            d2u_dx2 = tape2.gradient(du_dx, x)\n",
        "\n",
        "        # 3. dereceden tÃ¼rev\n",
        "        d3u_dx3 = tape3.gradient(d2u_dx2, x)\n",
        "\n",
        "    # 4. dereceden tÃ¼rev\n",
        "    d4u_dx4 = tape4.gradient(d3u_dx3, x)\n",
        "\n",
        "    # Kuramoto-Sivashinsky denklemi\n",
        "    # âˆ‚u/âˆ‚t + u*âˆ‚u/âˆ‚x + âˆ‚Â²u/âˆ‚xÂ² + âˆ‚â´u/âˆ‚xâ´ = 0\n",
        "    pde_residual = du_dt + u * du_dx + d2u_dx2 + d4u_dx4\n",
        "\n",
        "    # Cleanup\n",
        "    del tape1, tape2, tape3, tape4\n",
        "\n",
        "    return tf.reduce_mean(tf.square(pde_residual))\n",
        "\n",
        "# Periyodik sÄ±nÄ±r koÅŸulu\n",
        "def periodic_boundary_loss(model, x_left, x_right, t):\n",
        "    \"\"\"Periyodik sÄ±nÄ±r koÅŸulu: u(0,t) = u(2Ï€,t)\"\"\"\n",
        "    u_left = model(tf.stack([x_left, t], axis=1))\n",
        "    u_right = model(tf.stack([x_right, t], axis=1))\n",
        "\n",
        "    return tf.reduce_mean(tf.square(u_left - u_right))\n",
        "\n",
        "# Periyodik sÄ±nÄ±r koÅŸulu tÃ¼revler iÃ§in\n",
        "@tf.function\n",
        "def periodic_derivative_loss(model, x_left, x_right, t):\n",
        "    \"\"\"Periyodik sÄ±nÄ±r koÅŸulu tÃ¼revler iÃ§in: âˆ‚u/âˆ‚x(0,t) = âˆ‚u/âˆ‚x(2Ï€,t)\"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        tape.watch([x_left, x_right])\n",
        "        u_left = model(tf.stack([x_left, t], axis=1))\n",
        "        u_right = model(tf.stack([x_right, t], axis=1))\n",
        "\n",
        "    du_dx_left = tape.gradient(u_left, x_left)\n",
        "    du_dx_right = tape.gradient(u_right, x_right)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return tf.reduce_mean(tf.square(du_dx_left - du_dx_right))\n",
        "\n",
        "# BaÅŸlangÄ±Ã§ koÅŸulu\n",
        "def initial_condition_loss(model, x, t):\n",
        "    \"\"\"BaÅŸlangÄ±Ã§ koÅŸulu: u(x,0) = cos(x/16)*(1+sin(x/16))\"\"\"\n",
        "    u_pred = model(tf.stack([x, t], axis=1))\n",
        "\n",
        "    # BaÅŸlangÄ±Ã§ koÅŸulu - kaotik davranÄ±ÅŸ iÃ§in pertÃ¼rbasyonlu\n",
        "    u_initial = tf.cos(x/16) * (1 + tf.sin(x/16))\n",
        "\n",
        "    return tf.reduce_mean(tf.square(u_pred - u_initial))\n",
        "\n",
        "# Toplam loss fonksiyonu\n",
        "def total_loss(model, x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc):\n",
        "    \"\"\"Toplam loss: Physics + IC + BC\"\"\"\n",
        "\n",
        "    # Physics loss\n",
        "    physics = ks_physics_loss(model, x_pde, t_pde)\n",
        "\n",
        "    # Initial condition loss\n",
        "    initial = initial_condition_loss(model, x_ic, t_ic)\n",
        "\n",
        "    # Periodic boundary losses\n",
        "    boundary_val = periodic_boundary_loss(model, x_left, x_right, t_bc)\n",
        "    boundary_der = periodic_derivative_loss(model, x_left, x_right, t_bc)\n",
        "\n",
        "    return physics + 100 * initial + 50 * (boundary_val + boundary_der)\n",
        "\n",
        "# EÄŸitim verisi oluÅŸturma\n",
        "def generate_ks_training_data():\n",
        "    \"\"\"KS denklemi iÃ§in eÄŸitim verisi\"\"\"\n",
        "\n",
        "    # PDE noktalarÄ± (domain iÃ§i)\n",
        "    n_pde = 5000\n",
        "    x_pde = tf.random.uniform([n_pde], 0, L, dtype=tf.float32)\n",
        "    t_pde = tf.random.uniform([n_pde], 0, T, dtype=tf.float32)\n",
        "\n",
        "    # BaÅŸlangÄ±Ã§ koÅŸulu noktalarÄ± (t=0)\n",
        "    n_ic = 500\n",
        "    x_ic = tf.random.uniform([n_ic], 0, L, dtype=tf.float32)\n",
        "    t_ic = tf.zeros([n_ic], dtype=tf.float32)\n",
        "\n",
        "    # Periyodik sÄ±nÄ±r koÅŸulu noktalarÄ±\n",
        "    n_bc = 200\n",
        "    x_left = tf.zeros([n_bc], dtype=tf.float32)\n",
        "    x_right = tf.ones([n_bc], dtype=tf.float32) * L\n",
        "    t_bc = tf.random.uniform([n_bc], 0, T, dtype=tf.float32)\n",
        "\n",
        "    return x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc\n",
        "\n",
        "# EÄŸitim adÄ±mÄ±\n",
        "@tf.function\n",
        "def train_step(model, optimizer, x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = total_loss(model, x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Gradient clipping (numerical stability iÃ§in)\n",
        "    gradients = [tf.clip_by_norm(g, 1.0) for g in gradients]\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Model ve optimizer oluÅŸturma\n",
        "print(\"\\nModel oluÅŸturuluyor...\")\n",
        "model = create_ks_model()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# EÄŸitim verisi\n",
        "print(\"EÄŸitim verisi hazÄ±rlanÄ±yor...\")\n",
        "x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc = generate_ks_training_data()\n",
        "\n",
        "# EÄŸitim dÃ¶ngÃ¼sÃ¼\n",
        "print(\"KS-PINN eÄŸitimi baÅŸlÄ±yor...\")\n",
        "print(\"Bu kaotik bir sistem olduÄŸu iÃ§in eÄŸitim biraz uzun sÃ¼rebilir...\")\n",
        "\n",
        "losses = []\n",
        "epochs = 2000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss = train_step(model, optimizer, x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc)\n",
        "    losses.append(loss.numpy())\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    if epoch % 500 == 0 and epoch > 0:\n",
        "        optimizer.learning_rate = optimizer.learning_rate * 0.8\n",
        "\n",
        "    # Veri yenileme (kaotik sistem iÃ§in Ã¶nemli)\n",
        "    if epoch % 1000 == 0 and epoch > 0:\n",
        "        x_pde, t_pde, x_ic, t_ic, x_left, x_right, t_bc = generate_ks_training_data()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch:5d}, Loss: {loss:.6f}, LR: {optimizer.learning_rate.numpy():.6f}\")\n",
        "\n",
        "print(\"EÄŸitim tamamlandÄ±!\")\n",
        "\n",
        "# SonuÃ§larÄ± deÄŸerlendirme ve gÃ¶rselleÅŸtirme\n",
        "def evaluate_ks_solution():\n",
        "    \"\"\"KS Ã§Ã¶zÃ¼mÃ¼nÃ¼ deÄŸerlendir ve gÃ¶rselleÅŸtir\"\"\"\n",
        "\n",
        "    # Test grid'i\n",
        "    nx, nt = 200, 100\n",
        "    x_test = np.linspace(0, L, nx)\n",
        "    t_test = np.linspace(0, T, nt)\n",
        "    X, T_grid = np.meshgrid(x_test, t_test)\n",
        "\n",
        "    # PINN tahminleri\n",
        "    print(\"PINN Ã§Ã¶zÃ¼mÃ¼ hesaplanÄ±yor...\")\n",
        "    test_points = np.column_stack([X.flatten(), T_grid.flatten()])\n",
        "    u_pred = model(test_points.astype(np.float32)).numpy().reshape(X.shape)\n",
        "\n",
        "    return x_test, t_test, X, T_grid, u_pred\n",
        "\n",
        "# GÃ¶rselleÅŸtirme fonksiyonlarÄ±\n",
        "def plot_ks_results(x_test, t_test, X, T_grid, u_pred):\n",
        "    \"\"\"KS sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtir\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # 1. Spatio-temporal evolution\n",
        "    im1 = axes[0,0].contourf(X, T_grid, u_pred, levels=50, cmap='RdBu_r')\n",
        "    axes[0,0].set_title('KS Denklemi - Spatio-Temporal Evolution')\n",
        "    axes[0,0].set_xlabel('x')\n",
        "    axes[0,0].set_ylabel('t')\n",
        "    plt.colorbar(im1, ax=axes[0,0])\n",
        "\n",
        "    # 2. Solution at different times\n",
        "    times_to_plot = [0, T/4, T/2, 3*T/4, T]\n",
        "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
        "\n",
        "    for i, t_plot in enumerate(times_to_plot):\n",
        "        t_idx = int(t_plot * len(t_test) / T)\n",
        "        if t_idx >= len(t_test):\n",
        "            t_idx = len(t_test) - 1\n",
        "\n",
        "        axes[0,1].plot(x_test, u_pred[t_idx, :],\n",
        "                      color=colors[i], linewidth=2,\n",
        "                      label=f't = {t_plot:.1f}')\n",
        "\n",
        "    axes[0,1].set_title('Ã‡Ã¶zÃ¼m Profilleri (FarklÄ± Zamanlarda)')\n",
        "    axes[0,1].set_xlabel('x')\n",
        "    axes[0,1].set_ylabel('u(x,t)')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "\n",
        "    # 3. Time evolution at fixed points\n",
        "    x_points = [L/4, L/2, 3*L/4]\n",
        "    for i, x_point in enumerate(x_points):\n",
        "        x_idx = int(x_point * len(x_test) / L)\n",
        "        axes[1,0].plot(t_test, u_pred[:, x_idx],\n",
        "                      linewidth=2, label=f'x = {x_point:.2f}')\n",
        "\n",
        "    axes[1,0].set_title('Zaman Evrim (Sabit Noktalarda)')\n",
        "    axes[1,0].set_xlabel('t')\n",
        "    axes[1,0].set_ylabel('u(x,t)')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True)\n",
        "\n",
        "    # 4. Loss curve\n",
        "    axes[1,1].plot(losses, 'b-', linewidth=2)\n",
        "    axes[1,1].set_title('EÄŸitim Loss EÄŸrisi')\n",
        "    axes[1,1].set_xlabel('Epoch')\n",
        "    axes[1,1].set_ylabel('Loss')\n",
        "    axes[1,1].set_yscale('log')\n",
        "    axes[1,1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 3D gÃ¶rselleÅŸtirme\n",
        "def plot_3d_ks(x_test, t_test, X, T_grid, u_pred):\n",
        "    \"\"\"3D gÃ¶rselleÅŸtirme\"\"\"\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Surface plot\n",
        "    surf = ax.plot_surface(X, T_grid, u_pred, cmap='RdBu_r',\n",
        "                          alpha=0.8, edgecolor='none')\n",
        "\n",
        "    ax.set_title('Kuramoto-Sivashinsky Denklemi - 3D GÃ¶rÃ¼nÃ¼m')\n",
        "    ax.set_xlabel('x (Spatial)')\n",
        "    ax.set_ylabel('t (Time)')\n",
        "    ax.set_zlabel('u(x,t)')\n",
        "\n",
        "    # Colorbar\n",
        "    fig.colorbar(surf, ax=ax, shrink=0.5)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Kaotik Ã¶zellikler analizi\n",
        "def analyze_chaos(x_test, t_test, u_pred):\n",
        "    \"\"\"Kaotik Ã¶zellikleri analiz et\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"KAOTÄ°K Ã–ZELLÄ°KLER ANALÄ°ZÄ°\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Energy hesapla\n",
        "    energy = np.trapz(u_pred**2, x_test, axis=1)\n",
        "\n",
        "    # Dissipation rate hesapla (yaklaÅŸÄ±k)\n",
        "    dissipation = -np.gradient(energy, t_test)\n",
        "\n",
        "    print(f\"Maksimum amplitude: {np.max(np.abs(u_pred)):.4f}\")\n",
        "    print(f\"Minimum amplitude: {np.min(u_pred):.4f}\")\n",
        "    print(f\"BaÅŸlangÄ±Ã§ energy: {energy[0]:.4f}\")\n",
        "    print(f\"Son energy: {energy[-1]:.4f}\")\n",
        "    print(f\"Ortalama dissipation: {np.mean(dissipation[dissipation>0]):.4f}\")\n",
        "\n",
        "    # Energy evolution plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(t_test, energy, 'b-', linewidth=2)\n",
        "    plt.title('Energy Evolution')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('Energy')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(t_test[1:], dissipation[1:], 'r-', linewidth=2)\n",
        "    plt.title('Dissipation Rate')\n",
        "    plt.xlabel('t')\n",
        "    plt.ylabel('dE/dt')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ana Ã§alÄ±ÅŸtÄ±rma\n",
        "if __name__ == \"__main__\":\n",
        "    # Ã‡Ã¶zÃ¼mÃ¼ hesapla\n",
        "    x_test, t_test, X, T_grid, u_pred = evaluate_ks_solution()\n",
        "\n",
        "    # GÃ¶rselleÅŸtirmeler\n",
        "    plot_ks_results(x_test, t_test, X, T_grid, u_pred)\n",
        "    plot_3d_ks(x_test, t_test, X, T_grid, u_pred)\n",
        "\n",
        "    # Kaotik analiz\n",
        "    analyze_chaos(x_test, t_test, u_pred)\n",
        "\n",
        "    print(\"\\nğŸ‰ Kuramoto-Sivashinsky PINN modeli baÅŸarÄ±yla tamamlandÄ±!\")\n",
        "    print(\"Bu kaotik bir sistem olduÄŸu iÃ§in:\")\n",
        "    print(\"- KarmaÅŸÄ±k spatio-temporal yapÄ±lar gÃ¶rmelisiniz\")\n",
        "    print(\"- DÃ¼zensiz oscillasyonlar\")\n",
        "    print(\"- Energy dissipation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "ojZSPhcK13iL",
        "outputId": "bccdc986-0750-4e86-f9d4-45b69a3ab795"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kuramoto-Sivashinsky Denklemi PINN Modeli\n",
            "==================================================\n",
            "PDE: âˆ‚u/âˆ‚t + u*âˆ‚u/âˆ‚x + âˆ‚Â²u/âˆ‚xÂ² + âˆ‚â´u/âˆ‚xâ´ = 0\n",
            "Domain: x âˆˆ [0, 2Ï€], t âˆˆ [0, T]\n",
            "==================================================\n",
            "\n",
            "Model oluÅŸturuluyor...\n",
            "EÄŸitim verisi hazÄ±rlanÄ±yor...\n",
            "KS-PINN eÄŸitimi baÅŸlÄ±yor...\n",
            "Bu kaotik bir sistem olduÄŸu iÃ§in eÄŸitim biraz uzun sÃ¼rebilir...\n",
            "Epoch     0, Loss: 107.529999, LR: 0.001000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1fddc8396462>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_pde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_ic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_bc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGpvitSIChAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}